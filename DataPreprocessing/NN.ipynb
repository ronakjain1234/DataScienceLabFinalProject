{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ronak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ronak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ronak\\.cache\\kagglehub\\datasets\\saurabhshahane\\fake-news-classification\\versions\\77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# load datasets\n",
    "df=pd.read_csv(path+'/WELFake_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72134, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...      1\n",
       "1                                                NaN      1\n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...      1\n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...      0\n",
       "4  SATAN 2: Russia unvelis an image of its terrif...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'] = df['title'] + df['text']\n",
    "df = df[['article', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63121, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(subset='article', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_polarity'] = df['article'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df['sentiment_subjectivity'] = df['article'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.296824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190402</td>\n",
       "      <td>0.512798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111493</td>\n",
       "      <td>0.387106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>0.403577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100461</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...      1   \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...      1   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...      0   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...      1   \n",
       "5  About Time! Christian Group Sues Amazon and SP...      1   \n",
       "\n",
       "   sentiment_polarity  sentiment_subjectivity  \n",
       "0            0.034641                0.296824  \n",
       "2            0.190402                0.512798  \n",
       "3            0.111493                0.387106  \n",
       "4            0.013342                0.403577  \n",
       "5           -0.100461                0.428571  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping samples between train and test sets: 0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['article'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
    "overlap = set(X_train).intersection(set(X_test))\n",
    "print(f\"Number of overlapping samples between train and test sets: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b([a-zA-Z])\\.(?=[a-zA-Z])', r'\\1specialdot', text)  # Preserve acronyms\n",
    "    text = re.sub(r'\\b([a-zA-Z])\\.(?=\\s|$)', r'\\1specialdot', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = text.replace(\"specialdot\", \".\")\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.discard(\"not\")\n",
    "    stop_words.discard(\"no\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Vectorize text\n",
    "def vectorize(text, maxFeats, ngram):\n",
    "    vectorizer = TfidfVectorizer(max_features=maxFeats, ngram_range=ngram, stop_words='english')\n",
    "    X_tfidf = vectorizer.fit_transform(text)\n",
    "    return X_tfidf, vectorizer\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['article','sentiment_polarity','sentiment_subjectivity']], df['label'], \n",
    "    test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Preprocess data\n",
    "X_train_processed = X_train['article'].apply(preprocess_text)\n",
    "X_test_processed = X_test['article'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize data\n",
    "X_train_vectorized, vectorizer = vectorize(X_train_processed, 2000, (1,1))\n",
    "X_test_vectorized = vectorizer.transform(X_test_processed)\n",
    "\n",
    "# Train model\n",
    "#model = RandomForestClassifier()\n",
    "#model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "#y_pred = model.predict(X_test_vectorized)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "#print(f\"Test Set Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# # Cross-validation\n",
    "# scores = cross_val_score(model, X_train_vectorized, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Cross-validation Accuracies:\", scores)\n",
    "# print(\"Average Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorized_df = pd.DataFrame(X_train_vectorized)\n",
    "X_train_df = pd.concat([train_vectorized_df.reset_index(drop=True), X_train[['sentiment_polarity', 'sentiment_subjectivity']].reset_index(drop=True)], axis=1)\n",
    "test_vectorized_df = pd.DataFrame(X_test_vectorized)\n",
    "X_test_df = pd.concat([test_vectorized_df.reset_index(drop=True), X_test[['sentiment_polarity', 'sentiment_subjectivity']].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_matrix = vstack(X_train_df.iloc[:,0])\n",
    "train_dense_array = train_sparse_matrix.toarray()\n",
    "train_tensor_dense_array = torch.tensor(train_dense_array,dtype=torch.float32)\n",
    "\n",
    "train_numeric_df = X_train_df[['sentiment_polarity', 'sentiment_subjectivity']]\n",
    "train_data_array = train_numeric_df.to_numpy()\n",
    "train_data_tensor = torch.tensor(train_data_array,dtype=torch.float32)\n",
    "## Need to add train_data_tensor to the end of train_tensor_dense_array\n",
    "\n",
    "train_combined_tensor = torch.cat([train_tensor_dense_array,train_data_tensor],dim=1)\n",
    "\n",
    "\n",
    "test_sparse_matric = vstack(X_test_df.iloc[:,0])\n",
    "test_dense_array = test_sparse_matric.toarray()\n",
    "test_tensor_dense_array = torch.tensor(test_dense_array,dtype=torch.float32)\n",
    "\n",
    "test_numeric_df = X_test_df[['sentiment_polarity', 'sentiment_subjectivity']]\n",
    "test_data_array = test_numeric_df.to_numpy()\n",
    "test_data_tensor = torch.tensor(test_data_array,dtype=torch.float32)\n",
    "\n",
    "test_combined_tensor = torch.cat([test_tensor_dense_array,test_data_tensor], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.2176\n",
      "Epoch 2/30, Loss: 0.1438\n",
      "Epoch 3/30, Loss: 0.1073\n",
      "Epoch 4/30, Loss: 0.0753\n",
      "Epoch 5/30, Loss: 0.0500\n",
      "Epoch 6/30, Loss: 0.0352\n",
      "Epoch 7/30, Loss: 0.0248\n",
      "Epoch 8/30, Loss: 0.0211\n",
      "Epoch 9/30, Loss: 0.0201\n",
      "Epoch 10/30, Loss: 0.0156\n",
      "Epoch 11/30, Loss: 0.0147\n",
      "Epoch 12/30, Loss: 0.0138\n",
      "Epoch 13/30, Loss: 0.0111\n",
      "Epoch 14/30, Loss: 0.0113\n",
      "Epoch 15/30, Loss: 0.0102\n",
      "Epoch 16/30, Loss: 0.0104\n",
      "Epoch 17/30, Loss: 0.0099\n",
      "Epoch 18/30, Loss: 0.0095\n",
      "Epoch 19/30, Loss: 0.0091\n",
      "Epoch 20/30, Loss: 0.0100\n",
      "Epoch 21/30, Loss: 0.0086\n",
      "Epoch 22/30, Loss: 0.0084\n",
      "Epoch 23/30, Loss: 0.0082\n",
      "Epoch 24/30, Loss: 0.0075\n",
      "Epoch 25/30, Loss: 0.0068\n",
      "Epoch 26/30, Loss: 0.0097\n",
      "Epoch 27/30, Loss: 0.0077\n",
      "Epoch 28/30, Loss: 0.0070\n",
      "Epoch 29/30, Loss: 0.0069\n",
      "Epoch 30/30, Loss: 0.0068\n",
      "Test Accuracy: 0.9484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(train_combined_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(test_combined_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the neural network\n",
    "class FakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FakeNewsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # First hidden layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = train_combined_tensor.shape[1]\n",
    "model = FakeNewsClassifier(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predictions == y_batch).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/fake-news-detection?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41.0M/41.0M [00:01<00:00, 23.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ronak\\.cache\\kagglehub\\datasets\\bhavikjikadara\\fake-news-detection\\versions\\1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/fake-news-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# load datasets\n",
    "fake=pd.read_csv(path+'/fake.csv')\n",
    "fake['label'] = 0\n",
    "true=pd.read_csv(path+'/true.csv')\n",
    "true['label'] = 1\n",
    "test = pd.concat([fake, true])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['article'] = test['title'] + test['text']\n",
    "test = test[['article', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39105, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dropna(inplace=True)\n",
    "test.drop_duplicates(subset='article', inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083136</td>\n",
       "      <td>0.597204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020811</td>\n",
       "      <td>0.344802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>0.541969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.038021</td>\n",
       "      <td>0.413021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011722</td>\n",
       "      <td>0.495222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...      0   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...      0   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...      0   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...      0   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...      0   \n",
       "\n",
       "   sentiment_polarity  sentiment_subjectivity  \n",
       "0            0.083136                0.597204  \n",
       "1           -0.020811                0.344802  \n",
       "2           -0.012345                0.541969  \n",
       "3           -0.038021                0.413021  \n",
       "4           -0.011722                0.495222  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sentiment_polarity'] = test['article'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "test['sentiment_subjectivity'] = test['article'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = 1 - test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083136</td>\n",
       "      <td>0.597204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020811</td>\n",
       "      <td>0.344802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>0.541969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038021</td>\n",
       "      <td>0.413021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011722</td>\n",
       "      <td>0.495222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  label  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...      1   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...      1   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...      1   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...      1   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...      1   \n",
       "\n",
       "   sentiment_polarity  sentiment_subjectivity  \n",
       "0            0.083136                0.597204  \n",
       "1           -0.020811                0.344802  \n",
       "2           -0.012345                0.541969  \n",
       "3           -0.038021                0.413021  \n",
       "4           -0.011722                0.495222  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = test['article'], test['label']\n",
    "X = X.apply(preprocess_text)\n",
    "X = vectorizer.transform(X)\n",
    "# Predict and evaluate on test set\n",
    "# print(classification_report(y, y_pred))\n",
    "# print(f\"Test Set Accuracy: {accuracy_score(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_tensor1 = torch.tensor(X.toarray(),dtype=torch.float32)\n",
    "y_test_tensor1 = torch.tensor(y.values,dtype=torch.float32)\n",
    "\n",
    "test_dataset1 = TensorDataset(X_test_tensor1,y_test_tensor1)\n",
    "test_loader1 = DataLoader(test_dataset1,batch_size=32)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader1:\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predictions == y_batch).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {correct / total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on new test data\n",
    "test_data = [\n",
    "    {\"article\": \"Breaking news: The President announces a major economic reform to boost GDP growth.\", \"label\": 0},\n",
    "    {\"article\": \"Scientists claim that the Earth is flat and provide evidence at a recent conference.\", \"label\": 1},\n",
    "    {\"article\": \"Recent studies confirm the safety and effectiveness of COVID-19 vaccines worldwide.\", \"label\": 0},\n",
    "    {\"article\": \"A man in Ohio claims he saw an alien spaceship while walking his dog late at night.\", \"label\": 1},\n",
    "    {\"article\": \"The government has approved new environmental regulations to tackle climate change.\", \"label\": 0},\n",
    "    {\"article\": \"Fake story circulates on social media claiming that sugar cures all diseases.\", \"label\": 1},\n",
    "    {\"article\": \"The international summit on renewable energy has successfully concluded in Paris.\", \"label\": 0},\n",
    "    {\"article\": \"A viral post claims that drinking only water for a month can cure cancer.\", \"label\": 1},\n",
    "    {\"article\": \"Breaking: NASA confirms the discovery of a new habitable planet in a nearby star system.\", \"label\": 0},\n",
    "    {\"article\": \"Authorities warn about a rise in fake news websites spreading misinformation online.\", \"label\": 0}\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_data_df = pd.DataFrame(test_data)\n",
    "X1, y1 = test_data_df['article'], test_data_df['label']\n",
    "X1 = X1.apply(preprocess_text)\n",
    "X1 = vectorizer.transform(X1)\n",
    "# Predict and evaluate on test set\n",
    "# print(classification_report(y, y_pred))\n",
    "# print(f\"Test Set Accuracy: {accuracy_score(y, y_pred)}\")\n",
    "\n",
    "# Preprocess and vectorize test data\n",
    "#test_data_processed = test_data_df['article'].apply(preprocess_text)\n",
    "\n",
    "#test_data_vectorized = vectorizer.transform(test_data_processed)\n",
    "\n",
    "\n",
    "\n",
    "# Predict labels for test data\n",
    "#y_pred_test = model.predict(test_data_vectorized)\n",
    "\n",
    "# Evaluate model predictions\n",
    "#print(\"Predictions vs Ground Truth:\")\n",
    "#for text, pred, true in zip(test_data_df['article'], y_pred_test, test_data_df['label']):\n",
    " #   print(f\"News: {text}\\nPrediction: {'True' if pred == 1 else 'Fake'} | Ground Truth: {'True' if true == 1 else 'Fake'}\\n\")\n",
    "\n",
    "# Classification report for test data\n",
    "#print(classification_report(test_data_df['label'], y_pred_test, target_names=[\"Fake\", \"True\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_tensor2 = torch.tensor(X1.toarray(),dtype=torch.float32)\n",
    "y_test_tensor2 = torch.tensor(y1.values,dtype=torch.float32)\n",
    "\n",
    "test_dataset2 = TensorDataset(X_test_tensor2,y_test_tensor2)\n",
    "test_loader2 = DataLoader(test_dataset2,batch_size=1)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader2:\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predictions == y_batch).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {correct / total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
